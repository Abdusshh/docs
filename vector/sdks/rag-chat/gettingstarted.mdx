---
title: Getting Started
---

### Installation

<Tabs>
  <Tab title="npm">```bash npm install @upstash/rag-chat ```</Tab>
  <Tab title="pnpm">```bash pnpm install @upstash/rag-chat ```</Tab>
  <Tab title="bun">```bash bun install @upstash/rag-chat ```</Tab>
</Tabs>

### Usage

You can find the full API of this library in our [API documentation](http://localhost:3000/vector/sdks/rag-chat/methods) along with many examples in our [examples folder](https://github.com/upstash/rag-chat/tree/master/examples). The code below shows how to get started with a basic RAG chat.

```ts
import { RAGChat, openai } from "@upstash/rag-chat"

const ragChat = new RAGChat({
  model: openai("gpt-4.5-turbo", {
    apiKey: process.env.OPENAI_API_KEY, // This is the default and can be omitted
  }),
})

await ragChat.context.add(
  "Quantum JavaScript (Q.js) is a framework for writing quantum algorithms in JavaScript syntax."
)

const result = await ragChat.chat("Tell me about Q.js")
```

Create an Upstash vector database and grab the environment variables, they are used to store information in your knowledge base. Creating a vector database only takes a minute, but we have included a guide on [creating a vector database](https://upstash.com/docs/vector/overall/getstarted) just in case.

```bash .env
UPSTASH_VECTOR_REST_URL=
UPSTASH_VECTOR_REST_TOKEN=
```

---

### Adding data

We natively support ingesting entire web pages by URL, CSVs, PDFs, plain text and more. For example, this is how you would ingest a Wikipedia page:

```ts
await ragChat.context.add({
  type: "html",
  source: "https://en.wikipedia.org/wiki/Quantum_computing",

  // optional ðŸ‘‡: custom page parsing settings
  config: { chunkOverlap: 50, chunkSize: 200 },
})
```

or add a PDF:

```ts
await ragChat.context.add({
  type: "pdf",
  fileSource: "./data/quantum_computing_basics.pdf",

  // optional ðŸ‘‡: only add this knowledge to a specific user
  options: { namespace: "user-123-documents" },
})
```

### Chatting to your data

```ts
// get a response once the AI is done generating:
const response = await ragChat.chat("...")

// or stream a response as it's generated:
const streamedResponse = await ragChat.chat("...", { streaming: true })
```

You can read this stream directly or use our built-in adapters, for example in combination with [server actions](https://github.com/upstash/rag-chat/blob/master/examples/nextjs/server-actions/src/app/actions.ts) or the [Vercel AI SDK](https://github.com/upstash/rag-chat/blob/master/examples/nextjs/vercel-ai-sdk/src/app/api/chat/route.ts).

### Persisting messages (optional)

Provide Upstash Redis credentials for your chat history to automatically be persisted. See how to [create a Redis database here](https://upstash.com/docs/redis/overall/getstarted).

```bash .env
# Optional: for persisting messages
UPSTASH_REDIS_REST_URL=
UPSTASH_REDIS_REST_TOKEN=
```

## Troubleshooting

If you have any problems setting up or using RAG Chat, here are some common issues and their solutions:

1. Environment Variables: Make sure that all required environment variables are set correctly and accessible in your app.
2. API keys: Check that your OpenAI API key and Upstash credentials are valid.

If you still encounter a problem, please don't hesitate to contact our support! :)

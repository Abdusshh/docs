---
title: Cost
---

The Rate Limit SDK utilizes Upstash Redis in the background to monitor user requests. We've aimed to minimize the number of calls to lower both latency overhead and cost. Results are cached whenever possible, and we use Lua scripts to reduce the number of round trips. The count of commands executed by the RateLimit algorithm is contingent upon the chosen algorithm. More commands need execution during the first call in a process, while subsequent executions require fewer commands. If rate limit control fails (indicating the user has exceeded the rate and should be limited), the result is cached. Consecutive calls in the same process (or serverless function) are rejected until the period is over. This approach significantly aids in cost management during a DDoS attack.

Below is a simple analysis of how each algorithm behaves under different conditions. A cold start refers to the first time the rate limit method is called during the same process. This might be relevant if you're using the rate limit library in a serverless context. Your rate limit calls will be warm as long as your serverless function is warm.

### Fixed Algorithm

**Case 1: User is not rate limited (ratelimit.limit.success —> true)**

Cold start →  3 commands → EVAL, INCR, PEXPIRE

Warm start → 2 commands → EVAL, INCR

**Case 2: User is rate limited (ratelimit.limit.success —> false)**

Cold start →  2 commands → EVAL, INCR

Warm start → 0 commands

0 commands. No commands are consumed once the rate limit is reached, the result is cached.

If analytics enabled there is one extra command execution per call.

Analytics enabled → +1 commands → HINCRBY

### Sliding Window Algorithm

**Case 1: User is not rate limited (ratelimit.limit.success —> true)**

Cold start → 5 commands → EVAL, GET, GET, INCR, PEXPIRE

Warm start -> 4 commands → EVAL, GET, GET, INCR

**Case 2: User is rate limited (ratelimit.limit.success —> false)**

Cold start → 3 commands → EVAL, GET, GET

Warm start → 0 commands

0 commands. No commands are consumed once the rate limit is reached, the result is cached.

If analytics enabled there is one extra command execution per call.

Analytics enabled → +1 commands → HINCRBY

### Token Bucket Algorithm

**Case 1: User is not rate limited (ratelimit.limit.success —> true)**

Cold start → 4 commands → EVAL, HMGET, HMSET, PEXPIRE

Warm start → 4 commands → EVAL, HMGET, HMSET, PEXPIRE

**Case 2: User is rate limited (ratelimit.limit.success —> false)**

Cold start → 2 commands → EVAL, HMGET

Warm start → 0 commands

0 commands. No commands are consumed once the rate limit is reached, the result is cached.

If analytics enabled there is one extra command execution per call.

Analytics enabled → +1 commands → HINCRBY
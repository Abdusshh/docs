---
title: Getting Started
---

## Create your Vector instance

For the RAG chat to work, we need to create an Upstash Vector and get its credentials. To create an Upstash Vector, you can follow the [Upstash Vector "Get Started" guide](https://upstash.com/docs/vector/overall/getstarted).

## Create your Redis instance (Optional)

To be able to persist the chat history between refreshes/reloads we have to create an Upstash Redis and get its credentials. To create an Upstash Redis, you can follow the [Upstash Redis "Get Started" guide](https://upstash.com/docs/redis/overall/getstarted).
If you don't need persisted chat history you can still use our in-memory history. It's more than enough for simple cases. It's enabled by default.

## Add RAG Chat to Your Project

Once we have a Vector and Redis instance, next step is adding the RAG Chat to your project in its most basic form.

### Install RAG Chat

First, we need to install `@upstash/rag-chat`:

<Tabs>
  <Tab title="npm">
    ```bash
    npm install @upstash/rag-chat
    ```
  </Tab>
  <Tab title="pnpm">
    ```bash
    pnpm install @upstash/rag-chat
    ```
  </Tab>
  <Tab title="bun">
    ```bash
    bun install @upstash/rag-chat
    ```
  </Tab>
</Tabs>

### Add RAG Chat to Your Endpoint

Next step is to add RAG chat to your endpoint. In the example below, you can see how to initialize a RAG Chat and use it:

```ts
import { Index } from "@upstash/vector";
import { Redis } from "@upstash/redis";
import { RAGChat, openai } from "@upstash/rag-chat";

const ragChat = new RAGChat({
  model: openai("gpt-4.5-turbo", {
    apiKey: "YOUR_SECRET_KEY",
  }),
  vector: new Index({
    token: "YOUR_SECRET_KEY",
    url: "YOUR_SECRET_KEY",
  }),
  redis: new Redis({
    token: "YOUR_SECRET_KEY",
    url: "YOUR_SECRET_KEY",
  }),
});

await ragChat.context.add({
  type: "text",
  data: "Paris, the capital of France, is renowned for its iconic landmark, the Eiffel Tower, which was completed in 1889 and stands at 330 meters tall.",
});

const result = await ragChat.chat(
  "What year was the construction of the Eiffel Tower completed, and what is its height?",
  { streaming: false }
);
```

### Set Environment Variables

Final step is to update the environment variables so that the RAG Chat can create your instance without explicitly creating every helper component such as Redis, Index or LLM model.

Here is how you can set the environment variables in different cases:

<Tabs>
  <Tab title="Vercel">
    Go to the "Settings" tab in your project. In the menu to the left, click "Environment Variables".
    Add
    `UPSTASH_VECTOR_REST_TOKEN`,
    `UPSTASH_VECTOR_REST_URL`,
    `UPSTASH_REDIS_REST_URL`,
    `UPSTASH_REDIS_REST_TOKEN`,
    `OPENAI_API_KEY` and `QSTASH_TOKEN` environment variables and their values.
  </Tab>
  <Tab title="Cloudflare Worker (Wrangler)">
    Run:
    ```
    npx wrangler secret put UPSTASH_VECTOR_REST_URL
    ```
    When prompted, enter the value of `UPSTASH_VECTOR_REST_URL` when prompted. Do the same for rest of them:
    ```
    npx wrangler secret put UPSTASH_VECTOR_REST_TOKEN
    npx wrangler secret put OPENAI_API_KEY
    npx wrangler secret put QSTASH_TOKEN
    npx wrangler secret put UPSTASH_REDIS`REST_URL
    npx wrangler secret put UPSTASH_REDIS_REST_TOKEN
    ```
  </Tab>
  <Tab title="Local Nextjs Project">
    Go to the `.env.local` file and add the environment variables:
    ```
    UPSTASH_VECTOR_REST_URL="XXXXX"
    UPSTASH_VECTOR_REST_TOKEN="XXXXX"

    # if you use OpenAI compatible models
    OPENAI_API_KEY="XXXXX"

    # or if you use Upstash hosted models via QStash
    QSTASH_TOKEN="XXXXX"

    # Optional: For Redis-based chat history (default is in-memory)
    UPSTASH_REDIS_REST_URL="XXXXX"
    UPSTASH_REDIS_REST_TOKEN="XXXXX"
    ```
  </Tab>
</Tabs>

---
By setting these environment variables, you can simplify the initialization of RAG Chat. Instead of the detailed initialization shown earlier, you can use:

```ts
const ragChat = new RAGChat();
```

This simplified initialization relies on the properly set environment variables.

By default, RAG Chat tries to use the QStash LLM service if it's present. If not, it falls back to OpenAI. Nevertheless, OpenAI is still required for adding web pages into your Vector via `addContext`:

```ts
await ragChat.context.add({
  type: "html",
  source: "https://en.wikipedia.org/wiki/Quantum_computing",

  // optional ðŸ‘‡: custom page parsing settings
  config: { chunkOverlap: 50, chunkSize: 200 },
});
```

## Troubleshooting

If you encounter issues while setting up or using RAG Chat, here are some common problems and solutions:

1. Environment Variables: Ensure all required environment variables are correctly set and accessible in your application.
2. API Keys: Verify that your OpenAI API key and Upstash credentials are valid and have the necessary permissions.
3. Network Issues: Check your internet connection and ensure your application can reach the Upstash and OpenAI services.
4. Rate Limiting: Be aware of rate limits for both Upstash and OpenAI services, especially during high-volume usage.

For more detailed troubleshooting, reach out to the support channels for Upstash and OpenAI.

---
title: Overview
---
Upstash RAG Chat is a batteries-included retrieval-augmented generation (RAG) SDK that helps you build your RAG applications quickly.
RAG enhances AI responses by retrieving relevant information from a knowledge base before generating answers.
With Upstash RAG Chat, you don't have to worry about setting up different products like Redis, Vector databases, or LLMs. We've also abstracted away the complexities of frameworks like Langchain or LlamaIndex.

It's as easy as:

```ts
import { RAGChat } from "@upstash/rag-chat";

const ragChat = new RAGChat();

const response = await ragChat.chat("Tell me about machine learning");
console.log(response);
```

You can find the Github Repository [here](https://github.com/upstash/rag-chat).

## Features

### Integration and Compatibility
- Next.js compatibility with streaming support
- Built-in Vector store for your knowledge base
- (Optional) built-in Redis compatibility for fast chat history management

### Data Ingestion and Management
- Ingest entire websites, text files, CVSs, PDFs, and more out of the box
- (Optional) built-in rate limiting

### Flexibility
- (Optional) disableRag option to use it as LLM + chat history

## Architecture

  <img src="/img/sdk/rag-chat/architecture.png" width="100%" />

This diagram illustrates the flow of data in Upstash RAG Chat, from user input through the vector store and LLM to the final response.


## Use Cases

- Building custom chatbots with domain-specific knowledge
- Creating interactive documentation systems
- Developing AI-powered customer support tools
